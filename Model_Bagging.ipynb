{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap Aggregating (Bagging)\n",
    "\n",
    "Bagging is a homogeneous ensembling technique which uses samples of datasets for different independent estimators in a parrellel way and follows 'wisdom of crowd' principle. We have implemented bagging regressor with different base estimators along with famous RandomForest Regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import utils\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('dataset/df_train.csv')\n",
    "df_test = pd.read_csv('dataset/df_test.csv')\n",
    "target = df_train['SalePrice']\n",
    "df_train = df_train.drop(['SalePrice'], axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train, target, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################\n",
      "14:07:23\tRandom forest\n",
      "\n",
      "Regressor: \n",
      " RandomForestRegressor(bootstrap='auto', criterion='mse', max_depth=None,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=2, min_samples_split=4,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=1500,\n",
      "                      n_jobs=-1, oob_score=True, random_state=None, verbose=0,\n",
      "                      warm_start=False) \n",
      "\n",
      "14:08:05\tDone!\n",
      "####################################################\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "print('####################################################\\n{}\\tRandom forest'\n",
    "      .format(datetime.datetime.now().strftime('%H:%M:%S')))\n",
    "parameters={\n",
    "    'bootstrap':['auto'],\n",
    "    'max_features':['auto'],\n",
    "    'min_samples_leaf':[2],\n",
    "    'min_samples_split':[4],\n",
    "    'n_estimators': [1500],\n",
    "    'n_jobs':[-1],\n",
    "    'oob_score':[True]\n",
    "}\n",
    "\n",
    "r_forest = RandomForestRegressor()\n",
    "clf = GridSearchCV(r_forest, parameters, verbose=0, iid = False)\n",
    "clf.fit(X_train, y_train)\n",
    "random_forest = RandomForestRegressor(**clf.best_params_)\n",
    "\n",
    "print('\\nRegressor: \\n', random_forest, '\\n')\n",
    "print('{}\\tDone!\\n####################################################'\n",
    "      .format(datetime.datetime.now().strftime('%H:%M:%S')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging Regressors with different base estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "max_features = int(X_train.shape[1]/3)\n",
    "\n",
    "svr_bag = BaggingRegressor(base_estimator=SVR(), n_estimators=50, max_features=max_features ,oob_score=True)\n",
    "knn_bag = BaggingRegressor(base_estimator=KNeighborsRegressor(), n_estimators=50, max_features=max_features ,oob_score=True)\n",
    "#equivalent to Random Forest\n",
    "dt_bag = BaggingRegressor(base_estimator=DecisionTreeRegressor(), n_estimators=50, max_features=max_features ,oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting: \tRandom Forest\n",
      "Done!\n",
      "Fitting: \tBagging Decision Tree\n",
      "Done!\n",
      "Fitting: \tBagging SVM\n",
      "Done!\n",
      "Fitting: \tBagging KNN\n",
      "Done!\n",
      "=== Fitting Completed ! ====\n"
     ]
    }
   ],
   "source": [
    "#fitting the random forest model\n",
    "models = {\n",
    "    'Random Forest':r_forest,\n",
    "    'Bagging Decision Tree':dt_bag,\n",
    "    'Bagging SVM':svr_bag,\n",
    "    'Bagging KNN':knn_bag\n",
    "}\n",
    "\n",
    "df_metric = utils.fit_models(X_train, y_train, X_test, y_test, models)\n",
    "df_metric = df_metric.set_index('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>rmsle</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.143376</td>\n",
       "      <td>0.873579</td>\n",
       "      <td>0.011283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging Decision Tree</th>\n",
       "      <td>0.139650</td>\n",
       "      <td>0.880065</td>\n",
       "      <td>0.010968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging SVM</th>\n",
       "      <td>0.191927</td>\n",
       "      <td>0.773464</td>\n",
       "      <td>0.014935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging KNN</th>\n",
       "      <td>0.263972</td>\n",
       "      <td>0.571470</td>\n",
       "      <td>0.020407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           rmse        r2     rmsle\n",
       "model                                              \n",
       "Random Forest          0.143376  0.873579  0.011283\n",
       "Bagging Decision Tree  0.139650  0.880065  0.010968\n",
       "Bagging SVM            0.191927  0.773464  0.014935\n",
       "Bagging KNN            0.263972  0.571470  0.020407"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7693473954504522\n",
      "0.571373690285562\n",
      "0.8642768246230236\n"
     ]
    }
   ],
   "source": [
    "print(svr_bag.oob_score_)\n",
    "print(knn_bag.oob_score_)\n",
    "print(dt_bag.oob_score_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "From the above results we can see that Random Forest and Bagging done with Decision tree as base estimator which is also equivalent to random forest has the best predictions results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
